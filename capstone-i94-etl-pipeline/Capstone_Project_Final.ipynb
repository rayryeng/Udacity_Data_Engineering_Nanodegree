{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The goal of this project is to create an ETL pipeline using I94 immigration and city temperature data to create a database optimized for queries on immigration events. This database can be used to answer questions that are related to immigration behavior.\n",
    "\n",
    "The project follows these steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up\n",
    "\n",
    "Please note that this notebook is designed to be run on Udacity's notebook workspace as the data is provided internally by Udacity.  Also note that we will be using Pandas Redshift as a convenience method to upload our Pandas dataframes as tables to Amazon Redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas_redshift\n",
      "  Downloading https://files.pythonhosted.org/packages/9a/db/ca596f802f123d0c480675c04e3c83ba9fb7400d4510f8d12c0747e1b397/pandas_redshift-2.0.4-py3-none-any.whl\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from pandas_redshift) (1.9.7)\n",
      "Collecting psycopg2-binary (from pandas_redshift)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/1b/720b36697158113ca1b2221a8e96a470088ccf3770d182214689d1a96a07/psycopg2_binary-2.8.6-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.0MB 7.9MB/s eta 0:00:01    41% |█████████████▏                  | 1.2MB 11.0MB/s eta 0:00:01    65% |█████████████████████           | 1.9MB 17.4MB/s eta 0:00:01    94% |██████████████████████████████▎ | 2.8MB 19.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from pandas_redshift) (0.23.3)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.7 in /opt/conda/lib/python3.6/site-packages (from boto3->pandas_redshift) (1.12.7)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->pandas_redshift) (0.9.3)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /opt/conda/lib/python3.6/site-packages (from boto3->pandas_redshift) (0.1.13)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas->pandas_redshift) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas->pandas_redshift) (2017.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from pandas->pandas_redshift) (1.12.1)\n",
      "Requirement already satisfied: docutils>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.7->boto3->pandas_redshift) (0.14)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.20 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.7->boto3->pandas_redshift) (1.22)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas->pandas_redshift) (1.11.0)\n",
      "Installing collected packages: psycopg2-binary, pandas-redshift\n",
      "Successfully installed pandas-redshift-2.0.4 psycopg2-binary-2.8.6\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas_redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import pandas_redshift as pr\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "\n",
    "The intent of this project is to build a data warehouse on AWS Redshift and I plan on designing an ETL pipeline to load data into tables for OLAP.  The data that will be folded in will include sources from the I94 US Immigration dataaset provided by Udacity, as well as data that involves airport codes, US city demographics and data regarding temperature.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "\n",
    "The I94 immigration [data](https://travel.trade.gov/research/reports/i94/historical/2016.html) origtinates from the US National Tourism and Trade Office.  An additional intricacy is that is provided in SAS7BDAT [format](https://cran.r-project.org/web/packages/sas7bdat/vignettes/sas7bdat.pdf) and is a binary database storage format.  It contains international visitor arrival statistics by world regions and select countries (including top 20), type of visa, mode of transportation, age groups, states visited (first intended address only), and the top ports of entry (for select countries).  There are 12 parts of this datasets with over 40 million records combined.  However we will concentrate on the data that comes from April 2016 that consists of roughly 3 million records.  Some relevant attributes include:\n",
    "\n",
    "* `i94yr` - 4 digit year\n",
    "* `i94mon` - Numeric month\n",
    "* `i94cit` - 3 digit code of origin city\n",
    "* `i94port` - 3 character code of destination USA city\n",
    "* `arrdate` - Arrival date in the USA\n",
    "* `i94mode` - 1 digit travel code\n",
    "* `depdate` - Departure date from the USA\n",
    "* `i94visa` - Reason for immigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here - This takes some time to run.  Be patient.\n",
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first 5 elements of this dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Relevant Column Names to be used in our analysis\n",
    "Column Name|Description\n",
    "---|---\n",
    "*cicid*|ID that uniquely identify one record in the dataset\n",
    "i94yr | 4 digit year\n",
    "i94mon | Numeric month\n",
    "i94cit | 3 digit code of source city for immigration (Birth country)\n",
    "i94res | 3 digit code of source country for immigration (Residence country)\n",
    "i94port | Port admitted through\n",
    "arrdate | Arrival date in the USA\n",
    "i94mode | Mode of transportation (1 = Air, 2 = Sea, 3 = Land, 9 = Not reported)\n",
    "i94addr | State of arrival\n",
    "depdate | Departure date\n",
    "i94bir | Age (years) of respondent\n",
    "i94visa | Visa codes broken down into 3 categories: (1 = Business; 2 = Pleasure; 3 = Student)\n",
    "count | Used for summary statistics\n",
    "dtadfile | Character Date Field\n",
    "visapost | Department of State where where Visa was issued\n",
    "occup | Occupation to be performed in U.S.\n",
    "entdepa | Arrival Flag - Admitted or parolled into the US\n",
    "entdepd | Departure Flag - Departed, lost visa, or deceased\n",
    "entdepu | Update Flag - Update of visa, either apprehended, overstayed, or updated to permanent resident\n",
    "matflag | Match flag\n",
    "biryear | 4 digit year of birth\n",
    "dtaddto | Character date field to when admitted to the US\n",
    "gender | Gender\n",
    "insnum | INS number\n",
    "airline | Airline used to arrive in U.S.\n",
    "admnum | Admission number - Should be unique and not null\n",
    "fltno | Flight number of the airline used to arrive in the US\n",
    "visatype | Class of admission legally allowing the non-immigrant to temporarily stay in US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### US City Demographic Data\n",
    "\n",
    "[This dataset](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/) contains various information about the demographics of all US cities and census-designated places with a population greater or equal to 65,000.  This comes from the 2015 American Community Survey from the US Census Bureau's 2015 American Community Survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the US city demographics data and show the first 5 rows of the dataframe\n",
    "us_city_demographics_df = pd.read_csv('us-cities-demographics.csv', delimiter=';')\n",
    "us_city_demographics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "*I94 Immigration Data*\n",
    "\n",
    "The following columns have missing data:\n",
    "\n",
    "* `i94mode`\n",
    "* `i94bir`\n",
    "* `dtadfile`\n",
    "* `visapost`\n",
    "* `occup`\n",
    "* `entdepa`\n",
    "* `entdepd`\n",
    "* `entdepu`\n",
    "* `matflag`\n",
    "* `biryear`\n",
    "* `dtaddto`\n",
    "* `gender`\n",
    "* `insnum`\n",
    "* `airline`\n",
    "* `fltno`\n",
    "\n",
    "Due to this being missing, we will drop these columns.  \n",
    "\n",
    "The most important columns we will keep are:\n",
    "\n",
    "* `cicid` (naturally)\n",
    "* `i94yr`\n",
    "* `i94mon`,\n",
    "* `i94cit`\n",
    "* `i94res`\n",
    "* `i94port`\n",
    "* `arrdate`\n",
    "* `i94addr`\n",
    "* `depdate`\n",
    "* `i94visa`\n",
    "* `count`\n",
    "* `admnum`\n",
    "* `visatype`\n",
    "\n",
    "Let's display the total number of records for each column below.  Take note that we are dealing with 3,096,313 total records.  Any columns that don't have this amount are deemed missing and are removed from further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cicid       3096313\n",
       "i94yr       3096313\n",
       "i94mon      3096313\n",
       "i94cit      3096313\n",
       "i94res      3096313\n",
       "i94port     3096313\n",
       "arrdate     3096313\n",
       "i94mode     3096074\n",
       "i94addr     2943941\n",
       "depdate     2953856\n",
       "i94bir      3095511\n",
       "i94visa     3096313\n",
       "count       3096313\n",
       "dtadfile    3096312\n",
       "visapost    1215063\n",
       "occup          8126\n",
       "entdepa     3096075\n",
       "entdepd     2957884\n",
       "entdepu         392\n",
       "matflag     2957884\n",
       "biryear     3095511\n",
       "dtaddto     3095836\n",
       "gender      2682044\n",
       "insnum       113708\n",
       "airline     3012686\n",
       "admnum      3096313\n",
       "fltno       3076764\n",
       "visatype    3096313\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show non-null counts for each column of the immigration data\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "*US City Demographic Data*\n",
    "\n",
    "The following columns have missing data:\n",
    "\n",
    "* `Male Population`\n",
    "* `Female Population`\n",
    "* `Number of Veterans`\n",
    "* `Foreign-born`\n",
    "* `Average Household Size` \n",
    "\n",
    "We only interested in the `Total Population` in any case.  Take note that there are 2891 records for this dataset so any columns that don't match this should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                      2891\n",
       "State                     2891\n",
       "Median Age                2891\n",
       "Male Population           2888\n",
       "Female Population         2888\n",
       "Total Population          2891\n",
       "Number of Veterans        2878\n",
       "Foreign-born              2878\n",
       "Average Household Size    2875\n",
       "State Code                2891\n",
       "Race                      2891\n",
       "Count                     2891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the non-null counts for each column in the demographics data\n",
    "us_city_demographics_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### I94 Immigration Data\n",
    "As noted above, we will select out the relevant columns and remove the columns that are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Select out the relevant columns and drop any rows that are missing\n",
    "us_immigration_df = df[['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94addr', 'depdate', 'i94visa', 'count', 'admnum', 'visatype']]\n",
    "us_immigration_df = us_immigration_df.dropna()\n",
    "\n",
    "# There is an escape character with the i94addr column\n",
    "# Remove this using regular expressions where any repeated whitespace is removed\n",
    "us_immigration_df['i94addr'] = us_immigration_df['i94addr'].map(lambda col: re.sub('\\W+', '', col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>admnum</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.247104e+10</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20558.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.247140e+10</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate i94addr  depdate  \\\n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      MI  20691.0   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      MA  20567.0   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      MA  20567.0   \n",
       "5   18.0  2016.0     4.0   101.0   101.0     NYC  20545.0      MI  20555.0   \n",
       "6   19.0  2016.0     4.0   101.0   101.0     NYC  20545.0      NJ  20558.0   \n",
       "\n",
       "   i94visa  count        admnum visatype  \n",
       "2      2.0    1.0  6.666432e+08       B2  \n",
       "3      2.0    1.0  9.246846e+10       B2  \n",
       "4      2.0    1.0  9.246846e+10       B2  \n",
       "5      1.0    1.0  9.247104e+10       B1  \n",
       "6      2.0    1.0  9.247140e+10       B2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first 5 elements of this new dataframe\n",
    "us_immigration_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### US City Demographic Data\n",
    "As noted above, we select out the relevant columns.  Also note that we should drop duplicates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State Code</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Total Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MD</td>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>82463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MA</td>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>93629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>84839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>175232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NJ</td>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>281913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State Code              City          State  Total Population\n",
       "0         MD     Silver Spring       Maryland             82463\n",
       "1         MA            Quincy  Massachusetts             93629\n",
       "2         AL            Hoover        Alabama             84839\n",
       "3         CA  Rancho Cucamonga     California            175232\n",
       "4         NJ            Newark     New Jersey            281913"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select out the relevant columns and drop any duplicates\n",
    "us_city_demographics_df = us_city_demographics_df[['State Code', 'City', 'State', 'Total Population']].drop_duplicates()\n",
    "\n",
    "# Show the first 5 elements of this new dataframe\n",
    "us_city_demographics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "As we naturally learned in this course, we will use a more denormalized version of this combined data to minimize the amount of joins and to allow our data model to be used and interpreted in a more meaningful way.  Specifically, I chose to use the star schema with the immigration data serving as the fact table while the data that deals with dates and the states themselves are the dimension tables.  This will ultimately allow us to aggregate information about immigration based on fine grained time units, such as month or year as well the state itself.\n",
    "\n",
    "#### Fact Table\n",
    "\n",
    "`immigration`\n",
    "\n",
    "- Columns: *`cicid`*, `i94yr`, `i94mon`, `i94cit`, `i94res`, `i94port`, `arrdate`, `i94addr`, `depdate`, `i94visa`, `count`, `admnum`, `visatype`\n",
    "\n",
    "`cicid` will serve as the primary key\n",
    "\n",
    "#### Dimension Tables\n",
    "\n",
    "`date` - arrival and departure date in immigration broken down into specific units \n",
    "- *`sas_date`*, date, day, month, year, weekday\n",
    "\n",
    "`sas_date` will serve as the primary key.  This is a custom column that will be created here.  The SAS date is a value that represents the number of days between January 1, 1960, and a specified date.\n",
    "\n",
    "`state` - total population of the states\n",
    "- *`state_code`*, state, total_population\n",
    "\n",
    "`state_code` will serve as the primary key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "This will be outlined below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create the state table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Total Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1049629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>298695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>4499542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>589879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>24822460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Total Population\n",
       "0     Alabama           1049629\n",
       "1      Alaska            298695\n",
       "2     Arizona           4499542\n",
       "3    Arkansas            589879\n",
       "4  California          24822460"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We group all city population by state and aggregate by summing over them\n",
    "state_pop = us_city_demographics_df.groupby('State').sum().reset_index()\n",
    "state_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>state</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MD</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>1312129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>2015457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1049629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>24822460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NJ</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>1428908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code          state  population\n",
       "0         MD       Maryland     1312129\n",
       "1         MA  Massachusetts     2015457\n",
       "2         AL        Alabama     1049629\n",
       "3         CA     California    24822460\n",
       "4         NJ     New Jersey     1428908"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a right join to merge the state code and state together so we establish a mappin\n",
    "# between state code, the full name of the state as well as its population.\n",
    "state_pop_df = pd.merge(us_city_demographics_df[['State Code', 'State']].drop_duplicates(), state_pop, how='right', on='State')\n",
    "state_pop_df.columns = ['state_code', 'state', 'population']\n",
    "\n",
    "# Note we will rename these columns so that we can write to Redshift later for easy access\n",
    "state_pop_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create the date table\n",
    "\n",
    "For the SAS date, we will convert this into a readable date format that will allow us to do datetime processing with ease.  We'll do the same foro the departure date as well.\n",
    "\n",
    "We extract all values from arrdate and depdate and convert them into readable date format.\n",
    "\n",
    "We will first get the arrival date as a table in readable form and decompose the date into further units such as weekday, day, month and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Make a copy of the arrdate column for us to manipulate\n",
    "arrdate = us_immigration_df[['arrdate']].copy()\n",
    "# Rename the arrdate column to sas_date for final storage on Redshift\n",
    "arrdate = arrdate.rename(columns={\"arrdate\": \"sas_date\"})\n",
    "\n",
    "# Make this new column so that it provides date in readable format\n",
    "arrdate['date'] = arrdate['sas_date'].apply(lambda col: datetime.date(1960, 1, 1) + datetime.timedelta(days=col))\n",
    "\n",
    "# Also put in the weekday, day, month and year as new columns\n",
    "arrdate['weekday'] = arrdate['date'].apply(lambda col: col.weekday())\n",
    "arrdate['day'] = arrdate['date'].apply(lambda col: col.day)\n",
    "arrdate['month'] = arrdate['date'].apply(lambda col: col.month)\n",
    "arrdate['year'] = arrdate['date'].apply(lambda col: col.year)\n",
    "\n",
    "# Drop duplicates\n",
    "arrdate = arrdate.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sas_date</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20545.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101084</th>\n",
       "      <td>20546.0</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197740</th>\n",
       "      <td>20547.0</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290895</th>\n",
       "      <td>20548.0</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384303</th>\n",
       "      <td>20549.0</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sas_date        date  weekday  day  month  year\n",
       "2        20545.0  2016-04-01        4    1      4  2016\n",
       "101084   20546.0  2016-04-02        5    2      4  2016\n",
       "197740   20547.0  2016-04-03        6    3      4  2016\n",
       "290895   20548.0  2016-04-04        0    4      4  2016\n",
       "384303   20549.0  2016-04-05        1    5      4  2016"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(arrdate.shape)\n",
    "arrdate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Do the same for the depdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "depdate = us_immigration_df[['depdate']].copy()\n",
    "# Rename the arrdate column to sas_date for final storage on Redshift\n",
    "depdate = depdate.rename(columns={\"depdate\": \"sas_date\"})\n",
    "\n",
    "# Make new column so that it provides date in readable format\n",
    "depdate['date'] = depdate['sas_date'].apply(lambda col: datetime.date(1960, 1, 1) + datetime.timedelta(days=col))\n",
    "\n",
    "# Also put in the weekday, day, month and year as new columns\n",
    "depdate['weekday'] = depdate['date'].apply(lambda col: col.weekday())\n",
    "depdate['day'] = depdate['date'].apply(lambda col: col.day)\n",
    "depdate['month'] = depdate['date'].apply(lambda col: col.month)\n",
    "depdate['year'] = depdate['date'].apply(lambda col: col.year)\n",
    "\n",
    "# Drop duplicates\n",
    "depdate = depdate.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sas_date</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20691.0</td>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20567.0</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20555.0</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20558.0</td>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20553.0</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sas_date        date  weekday  day  month  year\n",
       "2   20691.0  2016-08-25        3   25      8  2016\n",
       "3   20567.0  2016-04-23        5   23      4  2016\n",
       "5   20555.0  2016-04-11        0   11      4  2016\n",
       "6   20558.0  2016-04-14        3   14      4  2016\n",
       "8   20553.0  2016-04-09        5    9      4  2016"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(depdate.shape)\n",
    "depdate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now that we have both arrival and departure dates, we should combine these into one final table as both the arrival and departure dates are both events we are interested in.  Simply do an outer join to help us accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "date = pd.merge(arrdate, depdate, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sas_date</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20545.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20546.0</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20547.0</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20548.0</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20549.0</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sas_date        date  weekday  day  month  year\n",
       "0   20545.0  2016-04-01        4    1      4  2016\n",
       "1   20546.0  2016-04-02        5    2      4  2016\n",
       "2   20547.0  2016-04-03        6    3      4  2016\n",
       "3   20548.0  2016-04-04        0    4      4  2016\n",
       "4   20549.0  2016-04-05        1    5      4  2016"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(date.shape)\n",
    "date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Moving the data onto Redshift\n",
    "\n",
    "Now that we've prepared our data seen above, let's move it onto Amazon Redshift.  Take note that this will use a configuration file that requires information that is sensitive, so on submission these are nulled out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dwh.cfg']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in attributes from custom config file to access S3 and Redshift\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Attributes for accessing Redshift cluster\n",
    "DWH_DB_USER = config.get(\"CLUSTER\", \"DB_USER\")\n",
    "DWH_DB_PASSWORD = config.get(\"CLUSTER\", \"DB_PASSWORD\")\n",
    "DWH_ENDPOINT = config.get(\"CLUSTER\", \"HOST\")\n",
    "DWH_PORT = config.get(\"CLUSTER\", \"DB_PORT\")\n",
    "DWH_DB = config.get(\"CLUSTER\", \"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Attributes for S3 access\n",
    "AWS_ACCESS_KEY = config.get(\"AWS\", \"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = config.get(\"AWS\", \"AWS_SECRET_ACCESS_KEY_ID\")\n",
    "AWS_BUCKET = config.get(\"AWS\", \"AWS_BUCKET\")\n",
    "AWS_BUCKET_SUBDIR = config.get(\"AWS\", \"AWS_BUCKET_SUBDIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Connect to Redshift cluster\n",
    "pr.connect_to_redshift(dbname=DWH_DB, host=DWH_ENDPOINT, port=DWH_PORT, user=DWH_DB_USER, password=DWH_DB_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Connect to S3\n",
    "pr.connect_to_s3(aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_ACCESS_KEY, bucket=AWS_BUCKET, subdirectory=AWS_BUCKET_SUBDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "`pandas_redshift.pandas_to_redshift` is a convenience method that will place our dataframe in an intermediate CSV form on a S3 bucket of our choice, then it will create a new table on Redshift based on this intermediate form.  Think of this as creating a staging table then final table in one sweep.  We will now place our tables on S3, then Redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Redshift | 2021-01-01 16:26:39,130 | pandas_redshift.core | INFO | saved file public.immigration-ee3aa726-d442-4a89-85dc-83a24e2032f4.csv in bucket capstone_data/public.immigration-ee3aa726-d442-4a89-85dc-83a24e2032f4.csv\n",
      "Pandas Redshift | 2021-01-01 16:26:39,144 | pandas_redshift.core | INFO | create table public.immigration (cicid REAL, i94yr REAL, i94mon REAL, i94cit REAL, i94res REAL, i94port VARCHAR(256), arrdate REAL, i94addr VARCHAR(256), depdate REAL, i94visa REAL, count REAL, admnum REAL, visatype VARCHAR(256)) diststyle even\n",
      "Pandas Redshift | 2021-01-01 16:26:39,148 | pandas_redshift.core | INFO | CREATING A TABLE IN REDSHIFT\n",
      "Pandas Redshift | 2021-01-01 16:26:39,390 | pandas_redshift.core | INFO | \n",
      "    copy public.immigration\n",
      "    from 's3://rayryeng-dend-capstone/capstone_data/public.immigration-ee3aa726-d442-4a89-85dc-83a24e2032f4.csv'\n",
      "    delimiter ','\n",
      "    ignoreheader 1\n",
      "    csv quote as '\"'\n",
      "    dateformat 'auto'\n",
      "    timeformat 'auto'\n",
      "    \n",
      "        access_key_id '********'\n",
      "        secret_access_key '********'\n",
      "        \n",
      "    \n",
      "    ;\n",
      "Pandas Redshift | 2021-01-01 16:26:39,394 | pandas_redshift.core | INFO | FILLING THE TABLE IN REDSHIFT\n"
     ]
    }
   ],
   "source": [
    "# Create US immigration fact table - Put on S3 then go to Redshift\n",
    "pr.pandas_to_redshift(data_frame=us_immigration_df, redshift_table_name = 'public.immigration', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Redshift | 2021-01-01 16:30:15,812 | pandas_redshift.core | INFO | saved file public.state-c4560e47-ab34-4ad5-8d1d-9ea9353f8c5f.csv in bucket capstone_data/public.state-c4560e47-ab34-4ad5-8d1d-9ea9353f8c5f.csv\n",
      "Pandas Redshift | 2021-01-01 16:30:15,816 | pandas_redshift.core | INFO | create table public.state (state_code VARCHAR(256), state VARCHAR(256), population BIGINT) diststyle even\n",
      "Pandas Redshift | 2021-01-01 16:30:15,820 | pandas_redshift.core | INFO | CREATING A TABLE IN REDSHIFT\n",
      "Pandas Redshift | 2021-01-01 16:30:16,063 | pandas_redshift.core | INFO | \n",
      "    copy public.state\n",
      "    from 's3://rayryeng-dend-capstone/capstone_data/public.state-c4560e47-ab34-4ad5-8d1d-9ea9353f8c5f.csv'\n",
      "    delimiter ','\n",
      "    ignoreheader 1\n",
      "    csv quote as '\"'\n",
      "    dateformat 'auto'\n",
      "    timeformat 'auto'\n",
      "    \n",
      "        access_key_id '********'\n",
      "        secret_access_key '********'\n",
      "        \n",
      "    \n",
      "    ;\n",
      "Pandas Redshift | 2021-01-01 16:30:16,066 | pandas_redshift.core | INFO | FILLING THE TABLE IN REDSHIFT\n"
     ]
    }
   ],
   "source": [
    "# Create state dimension table - Put on S3 then go to Redshift\n",
    "pr.pandas_to_redshift(data_frame=state_pop_df, redshift_table_name = 'public.state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Redshift | 2021-01-01 16:31:10,697 | pandas_redshift.core | INFO | saved file public.date-08be7eba-3d8c-4f3c-961d-8c70ff5ebf77.csv in bucket capstone_data/public.date-08be7eba-3d8c-4f3c-961d-8c70ff5ebf77.csv\n",
      "Pandas Redshift | 2021-01-01 16:31:10,702 | pandas_redshift.core | INFO | create table public.date (sas_date REAL, date VARCHAR(256), weekday BIGINT, day BIGINT, month BIGINT, year BIGINT) diststyle even\n",
      "Pandas Redshift | 2021-01-01 16:31:10,706 | pandas_redshift.core | INFO | CREATING A TABLE IN REDSHIFT\n",
      "Pandas Redshift | 2021-01-01 16:31:10,949 | pandas_redshift.core | INFO | \n",
      "    copy public.date\n",
      "    from 's3://rayryeng-dend-capstone/capstone_data/public.date-08be7eba-3d8c-4f3c-961d-8c70ff5ebf77.csv'\n",
      "    delimiter ','\n",
      "    ignoreheader 1\n",
      "    csv quote as '\"'\n",
      "    dateformat 'auto'\n",
      "    timeformat 'auto'\n",
      "    \n",
      "        access_key_id '********'\n",
      "        secret_access_key '********'\n",
      "        \n",
      "    \n",
      "    ;\n",
      "Pandas Redshift | 2021-01-01 16:31:10,953 | pandas_redshift.core | INFO | FILLING THE TABLE IN REDSHIFT\n"
     ]
    }
   ],
   "source": [
    "# Create date dimension table - Put on S3 then go to Redshift\n",
    "pr.pandas_to_redshift(data_frame=date, redshift_table_name = 'public.date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "We will perform integrity checks to ensure that our data is in a sane format.  This will include some sample queries made directly to the tables as well as checking the number of records for each table.  `pandas_redshift.redshift_to_pandas` is a nice function that allows us to provide a SQL query as a string and it returns a Pandas dataframe of the resulting query.\n",
    "\n",
    "##### 4.2.1 Number of rows should be non-zero\n",
    "Check to see if we have any tables that are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def data_quality_check(table):\n",
    "    \"\"\"\n",
    "    Checks to see if the total number of records is non-zero for a table\n",
    "    \n",
    "    Inputs:\n",
    "        table - String to denote our table to check\n",
    "    \n",
    "    Returns:\n",
    "        True/False to signify if number of records is non-zero\n",
    "    \"\"\"\n",
    "    return len(pr.redshift_to_pandas(f\"SELECT COUNT(*) FROM {table}\")) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for immigration\n",
      "Data quality check passed for state\n",
      "Data quality check passed for date\n"
     ]
    }
   ],
   "source": [
    "for table in ['immigration', 'state', 'date']:\n",
    "    if not data_quality_check(table):\n",
    "        print(f\"Data quality check failed. {table} returned no results.\")\n",
    "    else:\n",
    "        print(f\"Data quality check passed for {table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2.2 Check to see if there are any null primary keys\n",
    "\n",
    "Let's also check to see if there are any null records for the primary keys for the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def data_quality_check_null(table, column):\n",
    "    \"\"\"\n",
    "    Checks to see if there are any null records in a column\n",
    "    \n",
    "    Inputs:\n",
    "        table - String to denote our table to check\n",
    "        column - Column to check\n",
    "    \n",
    "    Returns:\n",
    "        True/False to signify if there are null records in a column\n",
    "    \"\"\"\n",
    "    return len(pr.redshift_to_pandas(f\"SELECT COUNT(*) FROM {table} WHERE {column} IS NULL\")) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for immigration, column cicid\n",
      "Data quality check passed for state, column state_code\n",
      "Data quality check passed for date, column sas_date\n"
     ]
    }
   ],
   "source": [
    "for table, column in zip(['immigration', 'state', 'date'], ['cicid', 'state_code', 'sas_date']):\n",
    "    if data_quality_check_null(table, column):\n",
    "        print(f\"Data quality check failed. {table} has null records for column {column}\")\n",
    "    else:\n",
    "        print(f\"Data quality check passed for {table}, column {column}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2.3 Check the first 20 records of our final tables\n",
    "\n",
    "Let's also do some simple checks on the actual contents.  Cycle through each table, grab 20 records and show them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "results = {table: pr.redshift_to_pandas(f\"SELECT * FROM {table} LIMIT 20\") for table in ['immigration', 'state', 'date']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>admnum</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.247100e+10</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20549.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.247890e+10</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.250770e+10</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.248630e+10</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20560.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.543190e+10</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.543370e+10</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>86.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>NH</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.545320e+10</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>94.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>CLT</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>SC</td>\n",
       "      <td>20546.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.544580e+10</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>105.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>DET</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20556.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.542590e+10</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>116.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.542250e+10</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>124.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20554.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.543650e+10</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>134.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.542150e+10</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>142.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.546130e+10</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>150.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.543660e+10</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>158.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20554.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.542210e+10</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>166.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>FTL</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.546250e+10</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>176.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20559.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.542660e+10</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>184.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>PA</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.542670e+10</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>197.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.542790e+10</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>208.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>20561.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.543420e+10</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate i94addr  depdate  \\\n",
       "0    18.0  2016.0     4.0   101.0   101.0     NYC  20545.0      MI  20555.0   \n",
       "1    28.0  2016.0     4.0   101.0   101.0     ATL  20545.0      MA  20549.0   \n",
       "2    39.0  2016.0     4.0   101.0   101.0     MIA  20545.0      FL  20574.0   \n",
       "3    51.0  2016.0     4.0   101.0   117.0     MIA  20545.0      FL  20555.0   \n",
       "4    69.0  2016.0     4.0   103.0   103.0     ATL  20545.0      FL  20560.0   \n",
       "5    78.0  2016.0     4.0   103.0   103.0     BOS  20545.0      MA  20548.0   \n",
       "6    86.0  2016.0     4.0   103.0   103.0     BOS  20545.0      NH  20550.0   \n",
       "7    94.0  2016.0     4.0   103.0   103.0     CLT  20545.0      SC  20546.0   \n",
       "8   105.0  2016.0     4.0   103.0   103.0     DET  20545.0      MI  20556.0   \n",
       "9   116.0  2016.0     4.0   103.0   103.0     NEW  20545.0      CA  20567.0   \n",
       "10  124.0  2016.0     4.0   103.0   103.0     NEW  20545.0      NJ  20554.0   \n",
       "11  134.0  2016.0     4.0   103.0   103.0     NEW  20545.0      NY  20547.0   \n",
       "12  142.0  2016.0     4.0   103.0   103.0     NEW  20545.0      NY  20550.0   \n",
       "13  150.0  2016.0     4.0   103.0   103.0     NEW  20545.0      NY  20553.0   \n",
       "14  158.0  2016.0     4.0   103.0   103.0     NEW  20545.0      NY  20554.0   \n",
       "15  166.0  2016.0     4.0   103.0   103.0     FTL  20545.0      FL  20553.0   \n",
       "16  176.0  2016.0     4.0   103.0   103.0     WAS  20545.0      FL  20559.0   \n",
       "17  184.0  2016.0     4.0   103.0   103.0     WAS  20545.0      PA  20553.0   \n",
       "18  197.0  2016.0     4.0   103.0   103.0     HOU  20545.0      TX  20548.0   \n",
       "19  208.0  2016.0     4.0   103.0   103.0     NYC  20545.0      GA  20561.0   \n",
       "\n",
       "    i94visa  count        admnum visatype  \n",
       "0       1.0    1.0  9.247100e+10       B1  \n",
       "1       1.0    1.0  9.247890e+10       B1  \n",
       "2       2.0    1.0  9.250770e+10       B2  \n",
       "3       2.0    1.0  9.248630e+10       B2  \n",
       "4       2.0    1.0  5.543190e+10       WT  \n",
       "5       2.0    1.0  5.543370e+10       WT  \n",
       "6       1.0    1.0  5.545320e+10       WB  \n",
       "7       2.0    1.0  5.544580e+10       WT  \n",
       "8       2.0    1.0  5.542590e+10       WT  \n",
       "9       2.0    1.0  5.542250e+10       WT  \n",
       "10      2.0    1.0  5.543650e+10       WT  \n",
       "11      2.0    1.0  5.542150e+10       WT  \n",
       "12      1.0    1.0  5.546130e+10       WB  \n",
       "13      2.0    1.0  5.543660e+10       WT  \n",
       "14      2.0    1.0  5.542210e+10       WT  \n",
       "15      2.0    1.0  5.546250e+10       WT  \n",
       "16      2.0    1.0  5.542660e+10       WT  \n",
       "17      1.0    1.0  5.542670e+10       WB  \n",
       "18      2.0    1.0  5.542790e+10       WT  \n",
       "19      2.0    1.0  5.543420e+10       WT  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['immigration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>state</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>2015457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PA</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2330856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CT</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>885581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>1711032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>990226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>398883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MO</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>1519194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CO</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>2935669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WA</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2500107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IA</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>733811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DE</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>71957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ME</td>\n",
       "      <td>Maine</td>\n",
       "      <td>66872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MD</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>1312129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NC</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>3060199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>2203460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>9815626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RI</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>413562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OH</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>2433689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MT</td>\n",
       "      <td>Montana</td>\n",
       "      <td>181294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AZ</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>4499542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_code           state  population\n",
       "0          MA   Massachusetts     2015457\n",
       "1          PA    Pennsylvania     2330856\n",
       "2          CT     Connecticut      885581\n",
       "3          GA         Georgia     1711032\n",
       "4          PR     Puerto Rico      990226\n",
       "5          ID           Idaho      398883\n",
       "6          MO        Missouri     1519194\n",
       "7          CO        Colorado     2935669\n",
       "8          WA      Washington     2500107\n",
       "9          IA            Iowa      733811\n",
       "10         DE        Delaware       71957\n",
       "11         ME           Maine       66872\n",
       "12         MD        Maryland     1312129\n",
       "13         NC  North Carolina     3060199\n",
       "14         MI        Michigan     2203460\n",
       "15         NY        New York     9815626\n",
       "16         RI    Rhode Island      413562\n",
       "17         OH            Ohio     2433689\n",
       "18         MT         Montana      181294\n",
       "19         AZ         Arizona     4499542"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sas_date</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20549.0</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20557.0</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20565.0</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20573.0</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20665.0</td>\n",
       "      <td>2016-07-30</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20610.0</td>\n",
       "      <td>2016-06-05</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20677.0</td>\n",
       "      <td>2016-08-11</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20630.0</td>\n",
       "      <td>2016-06-25</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20645.0</td>\n",
       "      <td>2016-07-10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20588.0</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20653.0</td>\n",
       "      <td>2016-07-18</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20712.0</td>\n",
       "      <td>2016-09-15</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20707.0</td>\n",
       "      <td>2016-09-10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20606.0</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20594.0</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20650.0</td>\n",
       "      <td>2016-07-15</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20644.0</td>\n",
       "      <td>2016-07-09</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20666.0</td>\n",
       "      <td>2016-07-31</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20685.0</td>\n",
       "      <td>2016-08-19</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20673.0</td>\n",
       "      <td>2016-08-07</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sas_date        date  weekday  day  month  year\n",
       "0    20549.0  2016-04-05        1    5      4  2016\n",
       "1    20557.0  2016-04-13        2   13      4  2016\n",
       "2    20565.0  2016-04-21        3   21      4  2016\n",
       "3    20573.0  2016-04-29        4   29      4  2016\n",
       "4    20665.0  2016-07-30        5   30      7  2016\n",
       "5    20610.0  2016-06-05        6    5      6  2016\n",
       "6    20677.0  2016-08-11        3   11      8  2016\n",
       "7    20630.0  2016-06-25        5   25      6  2016\n",
       "8    20645.0  2016-07-10        6   10      7  2016\n",
       "9    20588.0  2016-05-14        5   14      5  2016\n",
       "10   20653.0  2016-07-18        0   18      7  2016\n",
       "11   20712.0  2016-09-15        3   15      9  2016\n",
       "12   20707.0  2016-09-10        5   10      9  2016\n",
       "13   20606.0  2016-06-01        2    1      6  2016\n",
       "14   20594.0  2016-05-20        4   20      5  2016\n",
       "15   20650.0  2016-07-15        4   15      7  2016\n",
       "16   20644.0  2016-07-09        5    9      7  2016\n",
       "17   20666.0  2016-07-31        6   31      7  2016\n",
       "18   20685.0  2016-08-19        4   19      8  2016\n",
       "19   20673.0  2016-08-07        6    7      8  2016"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Finally close the cursor, commit and close the database connection, and remove variables from the environment.\n",
    "pr.close_up_shop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Dictionary\n",
    "#### Immigration\n",
    "\n",
    "Column Name | Description\n",
    "--- | ---\n",
    "*cicid*|ID that uniquely identify one record in the dataset\n",
    "i94yr | 4 digit year\n",
    "i94mon | Numeric month\n",
    "i94cit | 3 digit code of source city for immigration (Birth country)\n",
    "i94res | 3 digit code of source country for immigration (Residence country)\n",
    "i94port | Port admitted through\n",
    "arrdate | Arrival date in the USA.  This is the SAS date which is the number of days since January 1, 1960 that the subject arrived.\n",
    "i94addr | State of arrival\n",
    "depdate | Departure date\n",
    "i94visa | Visa codes broken down into 3 categories: (1 = Business; 2 = Pleasure; 3 = Student)\n",
    "count | Used for summary statistics\n",
    "admnum | Admission number - Should be unique and not null\n",
    "visatype | Class of admission legally allowing the non-immigrant to temporarily stay in US\n",
    "\n",
    "#### State\n",
    "\n",
    "Column Name | Description\n",
    "--- | ---\n",
    "*`state_code`* | Two letter state code representing the state\n",
    "`state` | Full name of the state\n",
    "`population`| Population of the state\n",
    "\n",
    "#### Date\n",
    "Column Name | Description\n",
    "--- | ---\n",
    "*`sas_date`* | The number of days since January 1, 1960 that the subject arrived\n",
    "`date` | Date in YYYY-MM-DD format\n",
    "`weekday` | If the day fell onto a weekday.  (1 = Monday, 2 = Tuesday, 3 = Wednesday, 4 = Thursday, 5 = Friday, 0 = Weekend)\n",
    "`day` | Code for which day of the week it was (1 = Monday, 2 = Tuesday, 3 = Wednesday, 4 = Thursday, 5 = Friday, 6 = Saturday, 7 = Sunday)\n",
    "`month` | Code for which month of the week it was (1 = January, 2 = February, 3 = March, 4 = April, 5 = May, 6 = June, 7 = July, 8 = August, 9 = September, 10 = October, 11 = November, 12 = December)\n",
    "`year` | Year\n",
    "\n",
    "### Primary Keys\n",
    "\n",
    "* `immigration`: `cicid`\n",
    "* `state`: `state_code`\n",
    "* `date`: `sas_date`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "We used a convenience library called [pandas-redshift](https://github.com/agawronski/pandas_redshift), which is designed to make it easier to get data from Amazon Redshift into a Pandas DataFrame and vice versa. It transfers the data frame to S3 and then to Redshift.  Of course we also used Amazon Redshift to set up the data warehouse and to perform our queries as seen above.\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    " \n",
    "    * For the I94 Immigration Data, it depends how often the immigration authorities update the data.  USCIS and related bodies within the government need to agree on a standard of access, updating and frequency so that the information can be synced with all agencies.  Since the data is on Amazon Redshift, we can easily provide access to this data and can agree on an update schedule and method.  For the US City Demographic Data, the data will be updated when there is another survey held by the US Census Bureau.\n",
    "\n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    "\n",
    "    * The data was increased by 100x. \n",
    " \n",
    "        * If the data was increased by 100x, pure pandas cannot handle it. We will need Spark to handle it.  The data can be split up into multiple batches which could be used to update the tables in an asynchronous mannter.\n",
    "    \n",
    "    * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "\n",
    "        * We can use Airflow to schedule a pipeline that run every day before 7am in this case.\n",
    "    \n",
    "    * The database needed to be accessed by 100+ people.\n",
    "\n",
    "        * The more people accessing the database the more CPU resources we need to get a fast experience.  By using a distributed database we can improve our replications and partitioning to get faster query results for each user.  However, our use of Redshift has the ability to be scalable for access so our current technology stack can support that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
