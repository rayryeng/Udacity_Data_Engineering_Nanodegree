{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## This section is to be run first so that the ETL pipeline is run to centralize / denormalize all of our data into a single table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    # join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "    # reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)  # Skip header\n",
    "        \n",
    "        # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Designing the right tables in Apache Cassandra for the right queries\n",
    "\n",
    "## After the ETL pipeline has run, a new CSV file called <font color=red>event_datafile_new.csv</font> is generated in the current directory.  This `event_datafile_new.csv` file contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "Below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## We will now begin to create and set the Keyspace on our local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TO-DO: Create a Keyspace \n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS udacity \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TO-DO: Set KEYSPACE to the keyspace specified above\n",
    "try:\n",
    "    session.set_keyspace('udacity')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Preamble - print out indices of the header and the columns themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 artist\n",
      "1 firstName\n",
      "2 gender\n",
      "3 itemInSession\n",
      "4 lastName\n",
      "5 length\n",
      "6 level\n",
      "7 location\n",
      "8 sessionId\n",
      "9 song\n",
      "10 userId\n"
     ]
    }
   ],
   "source": [
    "# Print out indices of the header and the columns themselves\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    header = next(csvreader) # skip header\n",
    "\n",
    "for i, h in enumerate(header):\n",
    "    print(i, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Query 1\n",
    "\n",
    "The following is the target query we wish to execute as the first query:\n",
    "\n",
    "> Give me the artist, song title and song's length in the music app history that was heard during `sessionId = 338` and `itemInSession = 4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step #1 - Create the table and form the query to probe the table\n",
    "\n",
    "The primary key was chosen to be the session ID as this makes sense to use this as the primary differentiator for each user's session and is guaranteed to be unique.  With each user session, there could be multiple items in session, though of course they don't all appear at the same time and reflect the user's choices in listening to different songs at any given time.  The item in session was chosen as a clustering key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## First create the table\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_information \"\n",
    "query = query + \"(session_id int, item_in_session int, artist_name text, song_title text, song_length float, PRIMARY KEY (session_id, item_in_session))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "## Query for probing the database once the table is complete\n",
    "query1 = 'SELECT artist_name, song_title, song_length FROM song_information WHERE session_id = 338 AND item_in_session = 4'                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step #2 - Read in denormalized data one row at a time and populate our table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        # Build INSERT query\n",
    "        query = \"INSERT INTO song_information (artist_name, song_title, song_length, session_id, item_in_session) \"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "        # Extract the elements of each linen in the denormalized CSV and place into table\n",
    "        session.execute(query, (line[0], line[9], float(line[5]), int(line[8]), int(line[3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step #3 - Do a SELECT to verify that the data have been inserted into each table\n",
    "\n",
    "Note that I have extracted each row from the `SELECT` statement and have placed them into a Pandas dataframe for easy reading.  Recall that the query was:\n",
    "\n",
    "> Give me the artist, song title and song's length in the music app history that was heard during `sessionId = 338` and `itemInSession = 4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_title</th>\n",
       "      <th>song_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Faithless</td>\n",
       "      <td>Music Matters (Mark Knight Dub)</td>\n",
       "      <td>495.307312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist_name                       song_title  song_length\n",
       "0   Faithless  Music Matters (Mark Knight Dub)   495.307312"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    rows = session.execute(query1)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "df = pd.DataFrame(columns=['artist_name', 'song_title', 'song_length'])\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "for row in rows:\n",
    "    df = df.append({'artist_name': row.artist_name, 'song_title': row.song_title, 'song_length': row.song_length}, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Query 2\n",
    "\n",
    "The following is the target query we wish to execute as the second query:\n",
    "\n",
    "> Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for `userid = 10`, `sessionid = 182`\n",
    "\n",
    "### Step #1 - Create the table and form the query to probe the table\n",
    "\n",
    "The primary key was chosen to be the user ID as this ID is guaranteed to be unique no matter which session we are in.  However, the user can have multiple sessions throughout the day, week, etc. so to further differentiate the time instance that the user was listening to a particular song, we further differentiate by session ID.  These two together should form a composite key to isolate out the particular time instance the user began his or her session thus forming our composite key.  To ensure we extract out the songs want to look at based on their unique session ID, we would like to sort the songs played during this session by `item_in_session`, so this leads using this as our clustering key.  Note that the user attribute is not required as a clustering key since the previous information up to this point is give us the necessary content we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## First create the table\n",
    "query = \"CREATE TABLE IF NOT EXISTS user_listening_history \"\n",
    "query = query + \"( user_id int, session_id int, item_in_session int, artist_name text, song_title text, user text, PRIMARY KEY ((user_id, session_id), item_in_session))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "## Query for probing the database once the table is complete\n",
    "query2 = 'SELECT artist_name, song_title, user, item_in_session FROM user_listening_history WHERE user_id = 10 AND session_id = 182'                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step #2 - Read in denormalized data one row at a time and populate our table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_listening_history (artist_name, song_title, user, user_id, session_id, item_in_session) \"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (line[0], line[9], line[1] + ' ' + line[4], int(line[10]), int(line[8]), int(line[3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step #3 - Do a SELECT to verify that the data have been inserted into each table\n",
    "\n",
    "Note that I have extracted each row from the `SELECT` statement and have placed them into a Pandas dataframe for easy reading.  Recall that the query was:\n",
    "\n",
    "> Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for `userid = 10`, `sessionid = 182`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_title</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Down To The Bone</td>\n",
       "      <td>Keep On Keepin' On</td>\n",
       "      <td>Sylvie Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three Drives</td>\n",
       "      <td>Greece 2000</td>\n",
       "      <td>Sylvie Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sebastien Tellier</td>\n",
       "      <td>Kilometer</td>\n",
       "      <td>Sylvie Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lonnie Gordon</td>\n",
       "      <td>Catch You Baby (Steve Pitron &amp; Max Sanna Radio Edit)</td>\n",
       "      <td>Sylvie Cruz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist_name                                            song_title  \\\n",
       "0   Down To The Bone                                    Keep On Keepin' On   \n",
       "1       Three Drives                                           Greece 2000   \n",
       "2  Sebastien Tellier                                             Kilometer   \n",
       "3      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio Edit)   \n",
       "\n",
       "          user  \n",
       "0  Sylvie Cruz  \n",
       "1  Sylvie Cruz  \n",
       "2  Sylvie Cruz  \n",
       "3  Sylvie Cruz  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    rows = session.execute(query2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "df = pd.DataFrame(columns=['artist_name', 'song_title', 'user'])\n",
    "for row in rows:\n",
    "    df = df.append({'artist_name': row.artist_name, 'song_title': row.song_title, 'user': row.user}, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Query 3\n",
    "\n",
    "The following is the target query we wish to execute as the second query:\n",
    "\n",
    "> Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "### Step #1 - Create the table and form the query to probe the table\n",
    "\n",
    "The primary key was chosen to be the song title and the clustering key was chosen to be the user name.  The reason why is because just cataloguing the information by using the song title alone does not take into account the multitude of users who could listen to the same song, which would mean that we would only ever get one row of a retrieved result.  Our desire is to find *all* users who listened to a particular song so we first partition the data based on the song that was listened to, then further decompose our data based on which users listened to which songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## First create the table\n",
    "query = \"CREATE TABLE IF NOT EXISTS list_users_for_song \"\n",
    "query = query + \"(song_title text, user text, PRIMARY KEY (song_title, user))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "## Query for probing the database once the table is complete\n",
    "query3 = \"SELECT song_title, user FROM list_users_for_song WHERE song_title = 'All Hands Against His Own'\"\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step #2 - Read in denormalized data one row at a time and populate our table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO list_users_for_song (song_title, user) \"\n",
    "        query = query + \"VALUES (%s, %s)\"\n",
    "        session.execute(query, (line[9], line[1] + ' ' + line[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step #3 - Do a SELECT to verify that the data have been inserted into each table\n",
    "\n",
    "Note that I have extracted each row from the `SELECT` statement and have placed them into a Pandas dataframe for easy reading.  Recall that the query was:\n",
    "\n",
    "> Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jacqueline Lynch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sara Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tegan Levine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user\n",
       "0  Jacqueline Lynch\n",
       "1      Sara Johnson\n",
       "2      Tegan Levine"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    rows = session.execute(query3)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "df = pd.DataFrame(columns=['user'])\n",
    "for row in rows:\n",
    "    df = df.append({'user': row.user}, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Drop the tables before closing out the sessions\n",
    "\n",
    "Now that we're finished with our three queries for this assignment, let's drop all of the tables for cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = 'DROP TABLE IF EXISTS song_information'\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "query = 'DROP TABLE IF EXISTS user_listening_history'\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "query = 'DROP TABLE IF EXISTS list_users_for_song'\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
